{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1234\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab_size = 20000\n",
    "learning_rate = 5e-3\n",
    "batch_size = 128\n",
    "num_epoch = 1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "url = \"https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\"\n",
    "wget.download(url, \"movie_data.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('./data/movie_data.csv.gz', 'rb') as f_in:\n",
    "    with open('./data/movie_data.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/movie_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "text = torchtext.legacy.data.Field(\n",
    "    tokenize=\"spacy\",\n",
    "    tokenizer_language= 'en_core_web_sm'\n",
    ")\n",
    "label = torchtext.legacy.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('TEXT_COLUMN_NAME', text), ('LABEL_COLUMN_NAME', label)]\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "    path=\"../data/movie_data.csv\", format='csv',\n",
    "    skip_header=True, fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATASET INTO TRAIN/VALIDATION/TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train_data: 37500\n",
      "Num test_data: 12500\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = dataset.split(\n",
    "    split_ratio=[0.75, 0.25],\n",
    "    random_state = random.seed(RANDOM_SEED)\n",
    ")\n",
    "print(f'Num train_data: {len(train_data)}')\n",
    "print(f'Num test_data: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train_data: 30000\n",
      "Num test_data: 7500\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = train_data.split(\n",
    "    split_ratio=[0.8, 0.2],\n",
    "    random_state = random.seed(RANDOM_SEED)\n",
    ")\n",
    "print(f'Num train_data: {len(train_data)}')\n",
    "print(f'Num test_data: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TEXT_COLUMN_NAME': ['Tatie', 'Danielle', 'is', 'all', 'about', 'a', 'ghastly', 'old', 'hag', 'who', 'torments', 'her', 'loving', 'and', 'oblivious', 'family', 'out', 'of', 'sheer', 'spite', '.', 'There', \"'s\", 'a', 'bit', 'of', 'subtext', 'that', 'might', 'be', 'about', 'France', \"'s\", 'colonial', 'past', 'but', 'it', \"'s\", 'mostly', 'just', 'Danielle', 'doing', 'the', 'sorts', 'of', 'things', '(', 'like', 'deliberately', 'abandoning', 'a', 'small', 'child', 'in', 'a', 'park', ')', 'that', 'would', 'soon', 'have', 'a', 'man', 'picking', 'up', 'his', 'teeth', 'with', 'broken', 'fingers', '.', 'Sadly', ',', 'that', 'does', \"n't\", 'happen', 'here', '.', 'It', 'looks', 'good', 'and', 'the', 'acting', 'is', 'fine', 'and', 'there', \"'s\", 'nothing', 'really', 'wrong', 'with', 'the', 'concept', 'but', 'it', \"'s\", 'just', 'so', 'SMUG', '.', 'God', ',', 'does', 'this', 'movie', 'love', 'itself', '.', 'Pity', 'it', 'is', \"n't\", 'nearly', 'as', 'clever', 'or', 'as', 'funny', 'as', 'it', 'thinks', 'it', 'is', '.', 'The', 'only', 'impetus', 'in', 'the', 'show', '-', 'sorry', ',', 'movie', '-', 'comes', 'from', 'Danielle', 'getting', 'nastier', 'and', 'nastier', ',', 'and', 'the', 'only', 'surprise', 'comes', 'from', 'watching', 'the', 'increasingly', 'improbable', 'ways', 'she', 'does', 'this', '.', 'That', \"'s\", 'right', ':', 'just', 'like', 'in', 'a', 'sitcom', ',', 'which', 'is', 'what', 'this', 'is', ',', 'with', 'the', 'added', \"'\", 'bonus', \"'\", 'of', 'delusions', 'of', 'grandeur', 'and', 'a', '110', '-', 'minute', 'running', 'time', '.'], 'LABEL_COLUMN_NAME': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "text.build_vocab(train_data, max_size=Vocab_size)\n",
    "label.build_vocab(train_data)\n",
    "print(f'Vocabulary size: {len(text.vocab)}')\n",
    "print(f'Number of classes: {len(label.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 345114), (',', 326502), ('.', 282237), ('a', 186104), ('and', 185901), ('of', 171857), ('to', 159083), ('is', 128952), ('in', 104713), ('I', 93719), ('it', 91379), ('that', 82954), ('\"', 76054), (\"'s\", 73553), ('this', 72321), ('-', 63183), ('/><br', 60606), ('was', 59986), ('with', 51064), ('as', 50939), ('movie', 50624), ('for', 50129), ('film', 46325), ('The', 45111), ('but', 41497), ('(', 39423), ('on', 39203), (\"n't\", 39079), (')', 38849), ('you', 36996), ('are', 35769), ('not', 34598), ('have', 33677), ('his', 32998), ('be', 32010), ('he', 29049), ('one', 28984), ('!', 26263), ('at', 26033), ('by', 25948), ('all', 25218), ('an', 24994), ('who', 24270), ('from', 23348), ('like', 23213), ('they', 23092), ('so', 21345), ('or', 20369), ('about', 20182), (\"'\", 20158), ('has', 20113), ('out', 20028), ('her', 19982), ('It', 19784), ('just', 19559), ('do', 18820), ('?', 17890), ('some', 17050), ('good', 16977), ('more', 16569), ('very', 15921), ('would', 15732), ('up', 15550), ('what', 15219), ('This', 15134), ('there', 14954), ('time', 14281), ('can', 14134), ('when', 13831), ('if', 13811), ('which', 13759), ('really', 13501), ('were', 13375), ('had', 13373), ('only', 13293), ('story', 13289), ('she', 13259), ('see', 13237), ('their', 13133), ('even', 13112), ('no', 12919), ('my', 12463), ('did', 12303), ('me', 12293), ('does', 11974), ('...', 11743), ('than', 11641), ('much', 11167), ('been', 10975), ('could', 10862), ('get', 10806), (':', 10697), ('into', 10639), ('well', 10607), ('him', 10340), ('people', 10331), ('other', 10311), ('will', 10301), ('bad', 10218), ('we', 10187)]\n"
     ]
    }
   ],
   "source": [
    "# 100 kí tự phổ biến nhất nhiều nhất\n",
    "print(text.vocab.freqs.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "# 10 kí tự đầu tiên\n",
    "print(text.vocab.itos[:10])\n",
    "# because of '<unk>', '<pad>', the vocab_size is 20002 but not 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# convert string to integer\n",
    "print(text.vocab.stoi['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'1': 0, '0': 1})\n",
      "Counter({'1': 15067, '0': 14933})\n"
     ]
    }
   ],
   "source": [
    "# class label\n",
    "print(label.vocab.stoi)\n",
    "# class label .count\n",
    "print(label.vocab.freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = \\\n",
    "    torchtext.legacy.data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data),\n",
    "        batch_size = batch_size,\n",
    "        sort_within_batch = False,\n",
    "        sort_key = lambda x: len(x.TEXT_COLUMN_NAME),\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([1070, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Validations\n",
      "Text matrix size: torch.Size([53, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Test\n",
      "Text matrix size: torch.Size([50, 128])\n",
      "Target vector size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_dataloader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nValidations')\n",
    "for batch in valid_dataloader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nTest')\n",
    "for batch in test_dataloader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD MODEL RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self,input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        # self.rnn = torch.nn.RNN(embedding_dim, hidden_dim, nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fullyconnected = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text_dim = [sentence_length, batch_size]\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # output_dim = [sentence_length, batch_size, hidden_dim]\n",
    "        # hidden_dim = [1, batch_size, hidden_dim]\n",
    "        \n",
    "        hidden.squeeze_(0) # bỏ sổ 1 trong hidden_dim \n",
    "        output = self.fullyconnected(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim=len(text.vocab), embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for idx, (features, targets) in enumerate(data_loader):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            logits = model(features)\n",
    "            _, prediction_labels = torch.max(logits, 1)\n",
    "            \n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (prediction_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_dataloader):\n",
    "        text = batch_data.TEXT_COLUMN_NAME.to(device)\n",
    "        labels = batch_data.LABEL_COLUMN_NAME.to(device)\n",
    "\n",
    "        # forward and backward\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # đạo hàm\n",
    "        loss.backward()\n",
    "\n",
    "        # update weight\n",
    "        optimizer.step()\n",
    "\n",
    "        if not batch_idx % 50:\n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epoch:03d} | '\n",
    "                f'Batch: {batch_idx:03d}/{len(train_dataloader):03d} | '\n",
    "                f'Loss: {loss: .4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "            f'{compute_accuracy(model, train_dataloader, device): .2f}'\n",
    "            f'\\nvalid accuracy: '\n",
    "            f'{compute_accuracy(model, valid_dataloader, device):.2f}%')\n",
    "    print(f'Time elapse: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_dataloader, device): .2f}%')\n",
    "\n",
    "torch.save(model, '../Movie Sentimentation/model/model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability positive:\n",
      "0.710697591304779\n",
      "Probability negative:\n",
      "0.2259497046470642\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = torch.load('../Movie Sentimentation/model/model1.pth', map_location=device)\n",
    "def predict_sentiment(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [text.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    return prediction[0][0].item()\n",
    "\n",
    "\n",
    "print('Probability positive:')\n",
    "print(predict_sentiment(model, \"This is a good movie I have ever seen.\"))\n",
    "\n",
    "print('Probability negative:')\n",
    "print(1-predict_sentiment(model, \"This is a very bac movie I have ever seen\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebcbe509b8a14b6a8304a33d89c3dad5930eeef2e9f65f4e60d00303eb4c0c2c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('P36_torch_venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
